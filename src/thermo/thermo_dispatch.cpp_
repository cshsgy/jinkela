// torch
#include <torch/torch.h>
#include <ATen/Dispatch.h>
#include <ATen/TensorIterator.h>
#include <ATen/native/cpu/Loops.h>
#include <ATen/native/ReduceOpsUtils.h>

// kintera
#include <kintera/index.h>
// #include "condensation_impl.h"

namespace kintera {

void call_condensation_cpu(at::TensorIterator& iter, int dim, int nvapor) {
  AT_DISPATCH_FLOATING_TYPES(iter.dtype(), "condensation_cpu", [&] {
    int nreact = at::native::ensure_nonempty_size(iter.output(), 0);
    iter.for_each([&](char** data, const int64_t* strides, int64_t n) {
      for (int i = 0; i < n; i++) {
        auto out = reinterpret_cast<scalar_t*>(data[0] + i * strides[0]);
        auto temp = reinterpret_cast<scalar_t*>(data[1] + i * strides[1]);
        auto pres = reinterpret_cast<scalar_t*>(data[2] + i * strides[2]);
        auto conc = reinterpret_cast<scalar_t*>(data[3] + i * strides[3]);
        auto svp_RT = reinterpret_cast<scalar_t*>(data[4] + i * strides[4]);
        auto logsvp_ddT = reinterpret_cast<scalar_t*>(data[5] + i * strides[5]);
        equilibrate_uv_rate_impl(out, conc, int_eng, svp_RT, logsvp_ddT,
                                 m_jac, m_stoich, nreact, nspecies);
      }
    });
  });
}

}  // namespace kintera
